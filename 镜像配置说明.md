# 国内镜像配置说明

## 已完成的修改

为解决中国大陆无法访问 Hugging Face 的问题，已对 `index.html` 进行以下修改：

### 1. UI 镜像源选择器

在"模型状态"下方添加了一个下拉菜单，用户可以自行选择下载源：

- **HF-Mirror** (推荐国内用户) - 使用 `hf-mirror.com` 镜像
- **ModelScope 镜像** (实验性) - 暂时仍使用 HF-Mirror (因 ModelScope 无 MLC 格式)
- **GitHub Proxy** - 使用 `hub.gitmirror.com` 和 `raw.gitmirror.com`
- **原始地址** (海外用户) - 直接访问 Hugging Face

### 2. 多镜像站支持

代码中预配置了多个镜像站（第 414-435 行）：

```javascript
const mirrorConfigs = {
    'hf-mirror': {
        huggingface: 'https://hf-mirror.com',
        github: 'https://ghp.ci/https://raw.githubusercontent.com'
    },
    'ghproxy': {
        huggingface: 'https://hub.gitmirror.com',
        github: 'https://raw.gitmirror.com'
    },
    // ... 更多镜像站
};
```

### 3. 工作原理

当用户点击"加载模型"按钮时：

1. 读取用户在下拉菜单中选择的镜像源
2. 根据选择，自动将所有 Hugging Face 和 GitHub 的 URL 替换为对应镜像
3. WebLLM 从镜像站下载 Qwen3-0.6B-q0f16-MLC 模型文件
4. 模型下载后缓存到浏览器，后续完全离线使用

## 如何使用

1. 打开应用后，在"下载源"下拉菜单中选择合适的镜像：
   - **国内用户**：选择"HF-Mirror"或"GitHub Proxy"
   - **海外用户**：选择"原始地址"

2. 点击"加载模型"按钮开始下载

3. 浏览器控制台会显示：`使用 XXX 镜像加载模型`

4. 如果某个镜像速度慢或失败，可以尝试其他镜像

## 添加自定义镜像站

如果您有其他镜像站，可以在 `index.html` 第 414-435 行添加：

```javascript
const mirrorConfigs = {
    'hf-mirror': {
        name: 'HF-Mirror',
        huggingface: 'https://hf-mirror.com',
        github: 'https://ghp.ci/https://raw.githubusercontent.com'
    },
    // 添加您的自定义镜像
    'custom': {
        name: '自定义镜像',
        huggingface: 'https://您的HF镜像地址',
        github: 'https://您的GitHub镜像地址'
    }
};
```

然后在 HTML 第 310-315 行的下拉菜单中添加选项：

```html
<select id="mirrorSelect">
    <option value="hf-mirror">HF-Mirror (推荐国内用户)</option>
    <option value="custom">自定义镜像</option>
    <!-- 其他选项... -->
</select>
```

## 可用镜像站列表

### 已内置的镜像站

1. **HF-Mirror** (推荐)
   - Hugging Face: `https://hf-mirror.com`
   - GitHub: `https://ghp.ci/https://raw.githubusercontent.com`

2. **GitHub Proxy**
   - Hugging Face: `https://hub.gitmirror.com`
   - GitHub: `https://raw.gitmirror.com`

### 其他可选镜像（需手动添加）

- `https://hf.co` (HF 短域名)
- `https://huggingface-cn.com`
- `https://cdn.jsdelivr.net/gh` (仅 GitHub，需调整路径格式)

## 测试步骤

1. 启动本地服务器：
   ```bash
   python3 -m http.server 8000
   ```

2. 浏览器访问 `http://localhost:8000`

3. 打开浏览器开发者工具（F12）查看控制台

4. 点击"加载模型"，应该会看到：
   - 控制台输出：`使用 HF-Mirror 国内镜像加载模型`
   - 进度条显示下载进度
   - 下载完成后提示"模型加载成功"

## 常见问题

**Q: 下载速度还是很慢？**
A:
- 镜像站可能有访问限制或流量限制
- 尝试更换其他镜像站
- 考虑使用代理或 VPN

**Q: 如何验证是否使用了镜像？**
A:
- 打开浏览器开发者工具
- 切换到 Network（网络）标签
- 点击"加载模型"
- 查看请求的 URL 是否指向镜像站

**Q: ModelScope 是否可用？**
A:
- ModelScope 上有 Qwen3-0.6B 原始模型，但没有 MLC 格式
- WebLLM 需要 MLC 格式的模型，目前只能从 Hugging Face 下载
- 建议使用 HF-Mirror 国内镜像

## 技术说明

### MLC 格式

- WebLLM 使用的模型格式是 MLC (Machine Learning Compilation)
- 经过特殊编译和优化，可以在浏览器中高效运行
- 文件包括：模型权重、配置文件、WebAssembly 库

### 模型大小

- Qwen3-0.6B-q0f16: 约 300-500MB
- 首次下载需要时间，请耐心等待
- 下载后永久缓存在浏览器中

## 参考资料

- HF-Mirror 镜像站: https://hf-mirror.com
- WebLLM 官方文档: https://webllm.mlc.ai/
- Qwen3 模型: https://github.com/QwenLM/Qwen3
